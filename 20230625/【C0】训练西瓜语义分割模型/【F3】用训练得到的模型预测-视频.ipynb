{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0a25e6-6f49-4f96-af23-b1e81fb10ab4",
   "metadata": {},
   "source": [
    "# 用训练得到的模型预测-视频\n",
    "\n",
    "同济子豪兄：https://space.bilibili.com/1900783\n",
    "\n",
    "2022-10-18 6-11 6-26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545b852-5e69-45b6-abbc-1483b7a434d6",
   "metadata": {},
   "source": [
    "## 进入 mmsegmentation 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24d56aa-5528-4561-bb1c-33bcffe2c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../mmsegmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3673e-a5f2-46f0-a87f-0069dd165485",
   "metadata": {},
   "source": [
    "## 视频预测-命令行（不推荐，慢）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792ec8de-1785-4d72-9f6f-704f596b6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python demo/video_demo.py \\\n",
    "#         data/street_20220330_174028.mp4 \\\n",
    "#         configs/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py \\\n",
    "#         https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221202_141901-28ad20f1.pth \\\n",
    "#         --device cuda:0 \\\n",
    "#         --output-file outputs/B3_video.mp4 \\\n",
    "#         --opacity 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd646001-89ad-4508-b709-717a18230316",
   "metadata": {},
   "source": [
    "## 视频预测-Python API（推荐，快）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fbae8-e700-41f4-8b75-c01224883dee",
   "metadata": {},
   "source": [
    "### 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bdbf74-66bb-4e0e-abb1-6e4f48a7f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import mmcv\n",
    "import mmengine\n",
    "from mmseg.apis import inference_model\n",
    "from mmseg.utils import register_all_modules\n",
    "register_all_modules()\n",
    "\n",
    "from mmseg.datasets import CityscapesDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ff19c-ae76-4203-aa61-b2c2f105c6ad",
   "metadata": {},
   "source": [
    "### 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6710ee9f-d7b9-4ca7-ba84-84499ec5353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型 config 配置文件\n",
    "config_file = 'pspnet-ZihaoDataset_20230625.py'\n",
    "\n",
    "# 模型 checkpoint 权重文件\n",
    "checkpoint_file = './work_dirs/ZihaoDataset/iter_12000.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c891afa1-1f5f-4a16-ae38-97b72c5966a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/featurize/work/MMSegmentation教程20230625/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/home/featurize/work/MMSegmentation教程20230625/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:236: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  'Default ``avg_non_ignore`` is False, if you would like to '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ./work_dirs/ZihaoDataset/iter_12000.pth\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import init_model\n",
    "model = init_model(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "from mmengine.model.utils import revert_sync_batchnorm\n",
    "if not torch.cuda.is_available():\n",
    "    model = revert_sync_batchnorm(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81912ec-c8ff-4d63-8c4b-f0b9eab00da7",
   "metadata": {},
   "source": [
    "### 输入视频路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ae61f8-23ec-4f99-8951-ebc1522280b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_video = 'data/traffic.mp4'\n",
    "\n",
    "input_video = 'data/street_20220330_174028.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc3f035-8390-4be4-aefe-770990a04f78",
   "metadata": {},
   "source": [
    "### 创建临时文件夹，存放每帧结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d92a9e1-040d-4c4b-881d-f16053086db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建临时文件夹 20230625215355 用于存放每帧预测结果\n"
     ]
    }
   ],
   "source": [
    "temp_out_dir = time.strftime('%Y%m%d%H%M%S')\n",
    "os.mkdir(temp_out_dir)\n",
    "print('创建临时文件夹 {} 用于存放每帧预测结果'.format(temp_out_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1911cfc-58b1-4121-94a9-c6e8a779f036",
   "metadata": {},
   "source": [
    "## 视频单帧预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cd07f0-80dd-4fab-923a-719bc6ba22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 Cityscapes 街景数据集 类别名和调色板\n",
    "from mmseg.datasets import cityscapes\n",
    "classes = cityscapes.CityscapesDataset.METAINFO['classes']\n",
    "palette = cityscapes.CityscapesDataset.METAINFO['palette']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2f0568-50c6-4816-b820-cf597a5ef099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pridict_single_frame(img, opacity=0.2):\n",
    "    \n",
    "    result = inference_model(model, img)\n",
    "    \n",
    "    # 将分割图按调色板染色\n",
    "    seg_map = np.array(result.pred_sem_seg.data[0].detach().cpu().numpy()).astype('uint8')\n",
    "    seg_img = Image.fromarray(seg_map).convert('P')\n",
    "    seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "    \n",
    "    show_img = (np.array(seg_img.convert('RGB')))*(1-opacity) + img*opacity\n",
    "    \n",
    "    return show_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3f5bf-f6fa-4f3b-832a-e84ce7437ed1",
   "metadata": {},
   "source": [
    "### 视频逐帧预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b53cf47-d1eb-4b77-97bd-8ce01dc3cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/159, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.7/site-packages/mmdet/models/layers/positional_encoding.py:84: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
      "/environment/miniconda3/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 138/138, 23.9 task/s, elapsed: 6s, ETA:     0s[                                                  ] 0/138, elapsed: 0s, ETA:\n",
      "删除临时文件夹 20230625215355\n"
     ]
    }
   ],
   "source": [
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "\n",
    "prog_bar = mmengine.ProgressBar(len(imgs))\n",
    "\n",
    "# 对视频逐帧处理\n",
    "for frame_id, img in enumerate(imgs):\n",
    "    \n",
    "    ## 处理单帧画面\n",
    "    show_img = pridict_single_frame(img, opacity=0.15)\n",
    "    temp_path = f'{temp_out_dir}/{frame_id:06d}.jpg' # 保存语义分割预测结果图像至临时文件夹\n",
    "    cv2.imwrite(temp_path, show_img)\n",
    "\n",
    "    prog_bar.update() # 更新进度条\n",
    "\n",
    "# 把每一帧串成视频文件\n",
    "mmcv.frames2video(temp_out_dir, 'outputs/B3_video.mp4', fps=imgs.fps, fourcc='mp4v')\n",
    "\n",
    "shutil.rmtree(temp_out_dir) # 删除存放每帧画面的临时文件夹\n",
    "print('删除临时文件夹', temp_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a60b03-f55d-4e86-b336-9f562f3eb59f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
